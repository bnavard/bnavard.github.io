<!DOCTYPE HTML>
<html lang="en">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
      <title>Pouyan Navard</title>
      <meta name="author" content="Pouyan B. Navard">
      <meta name="viewport" content="width=device-width, initial-scale=1">
      <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
      <link rel="stylesheet" type="text/css" href="stylesheet.css">
   </head>
   <body>
      <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
         <tbody>
            <tr style="padding:0px">
               <td style="padding:0px">
                  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                     <tbody>
                        <tr style="padding:0px">
                           <td style="padding:2.5%;width:63%;vertical-align:middle">
                              <p class="name" style="text-align: center;">
                                 Pouyan Navard
                              </p>
                              <p>
                                 I'm a computer vision engineer at <a href="https://www.path-robotics.com/" target="_blank">Path Robotics Inc.</a> working on GenAI models for robot learning applications. I did my PhD at <a href="https://www.osu.edu/">The Ohio State University</a>, where I was advised by <a href="https://ceg.osu.edu/people/yilmaz.15">Alper Yilmaz</a>. 
                                 During my PhD I focused on self-supervised representation learning on 3D volumetric images. I've received the <a href="https://my.asprs.org/2022Conference/2022Conference/Awards---Scholarships.aspx">Robert E. Altenhofen Memorial Scholarship</a>.
                              </p>
                              <p style="text-align:center">
                                 <a href="mailto:bnd.pouyan@gmail.com" target="_blank">Email</a> &nbsp;/&nbsp;
                                 <a href="data/pouyan_cv.pdf" target="_blank">CV</a> &nbsp;/&nbsp;
                                 <a href="https://scholar.google.com/citations?user=Zlac41oAAAAJ&hl=en" target="_blank">Scholar</a> &nbsp;/&nbsp;
                                 <a href="https://www.linkedin.com/in/pouyan-boreshnavard/" target="_blank">LinkedIn</a> &nbsp;/&nbsp;
                                 <a href="https://github.com/bnavard/" target="_blank">Github</a>
                              </p>
                           </td>
                           <td style="padding:2.5%;width:37%;max-width:37%">
                              <a href="images/PouyanNavard.jpeg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/PouyanNavard.jpeg" class="hoverZoomLink"></a>
                           </td>
                        </tr>
                     </tbody>
                  </table>
                  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                     <tbody>
                        <tr>
                           <td style="padding:16px;width:100%;vertical-align:middle">
                              <h2>Research</h2>
                              <p>
                                 I’m on an exciting journey exploring the fascinating world of computer vision, deep learning, and generative AI. My work focuses on building and fine-tuning advanced AI models, then diving deep into explainable AI (XAI) to uncover why they succeed—or where they go wrong. I’m driven by the challenge of translating the magic of these black-box models into clear insights, from tracking down root causes of failure to discovering what makes them tick.
                              </p>
                           </td>
                        </tr>
                     </tbody>
                  </table>
                  <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                     <tbody>
                        <!-- KnobGen Paper -->
                        <tr onmouseout="knobgen_stop()" onmouseover="knobgen_start()"  bgcolor="#ffffd0">
                           <td style="padding:16px;width:20%;vertical-align:middle">
                              <div class="one">
                                 <div class="two" id='knobgen_image'>
                                    <video  width=100% height=100% muted autoplay loop>
                                       <source src="images/knobgen_transition.mp4" type="video/mp4">
                                       Your browser does not support the video tag.
                                    </video>
                                 </div>
                                 <img src='images/knob_gen.jpg' width="160">
                              </div>
                              <script type="text/javascript">
                                 function knobgen_start() {
                                   document.getElementById('knobgen_image').style.opacity = "1";
                                 }
                                 
                                 function knobgen_stop() {
                                   document.getElementById('knobgen_image').style.opacity = "0";
                                 }
                                 knobgen_stop()
                              </script>
                           </td>
                           <td style="padding:8px;width:80%;vertical-align:middle">
							  <span class="papertitle">KnobGen: Controlling the Sophistication of Artwork in Sketch-Based Diffusion Models</span>
                              <br>
							  <div style="margin-top: 7px;"></div> <!-- vertical space -->
                              <strong>Pouyan Navard</strong>,
                              Amin Karimi Monsefi,
                              Mengxi Zhou,
                              Wei-Lun Chao,
                              Alper Yilmaz, 
                              Rajiv Ramnath
                              <br>
                              <em>CVPR 2025, <a href="https://cveu.github.io/" target="_blank">CVEU</a></em>
                              <br>
                              <a href="https://github.com/aminK8/KnobGen" target="_blank">project page</a>
                              /
                              <a href="https://arxiv.org/abs/2410.01595" target="_blank">arXiv</a>
                              <p></p>
                              <p>
                                 We introduce KnobGen, a dual-pathway framework that bridges the gap between novice sketches and expert-level image generation. 
                                 Our system dynamically balances fine-grained detail and high-level control using adjustable modules, high-quality results from any sketch.
                              </p>
                           </td>
                        </tr>
                        <!-- SegFormer3D Paper -->
                        <tr onmouseout="segformer3d_stop()" onmouseover="segformer3d_start()" bgcolor="#ffffd0">
                           <td style="padding: 16px; width: 20%; vertical-align: middle;">
                              <div style="position: relative; width: 160px; height: auto;">
                                 <!-- The still image -->
                                 <img src="images/segformer3d.jpeg" width="160" style="display: block; width: 100%; height: auto; transform: translateY(1.5px);">
                                 <!-- The video overlay -->
                                 <div id="segformer3d_image" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; opacity: 0; transition: opacity 0.3s;">
                                    <video width="100%" height="100%" muted autoplay loop>
                                       <source src="images/segformer3d_transition.mp4" type="video/mp4">
                                       Your browser does not support the video tag.
                                    </video>
                                 </div>
                              </div>
                              <script type="text/javascript">
                                 function segformer3d_start() {
                                 document.getElementById('segformer3d_image').style.opacity = "1";
                                 }
                                 
                                 function segformer3d_stop() {
                                 document.getElementById('segformer3d_image').style.opacity = "0";
                                 }
                                 segformer3d_stop();
                              </script>
                           </td>
                           <td style="padding: 8px; width: 80%; vertical-align: middle;">
                              <span class="papertitle">SegFormer3D: an Efficient Transformer for 3D Medical Image Segmentation</span>
                              <br>
							  <div style="margin-top: 7px;"></div> <!-- vertical space -->
                              Shehan Pererra, <strong>Pouyan Navard</strong>, Alper Yilmaz
                              <br>
                              <em>CVPR 2024, 
                              <a href="https://cvpr.thecvf.com/virtual/2024/workshop/23663">DEF-AI-MIA</a>
                              </em>
                              <br>
                              <a href="https://github.com/OSUPCVLab/SegFormer3D">project page</a> /
                              <a href="https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Perera_SegFormer3D_An_Efficient_Transformer_for_3D_Medical_Image_Segmentation_CVPRW_2024_paper.html">CVF</a>
                              <p>
                                 SegFormer3D redefines 3D medical image segmentation with a lightweight hierarchical Transformer that rivals state-of-the-art models. By blending multi-scale volumetric attention with an all-MLP decoder, we achieve competitive accuracy while slashing parameter counts and compute needs.
                              </p>
                           </td>
                        </tr>
                     </tbody>
                  </table>
                  <table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;">
                     <tbody>
                        <tr>
                           <td>
                              <h2>Miscellanea</h2>
                           </td>
                        </tr>
                     </tbody>
                  </table>
                  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                     <tbody>
                        <tr>
                           <td align="center" style="padding:16px;width:20%;vertical-align:middle">
                              <div class="colored-box" style="background-color: #fcb97d;">
                                 <h2>Micropapers</h2>
                              </div>
                           </td>
                           <td style="padding:8px;width:80%;vertical-align:middle">
                              <a href="">A Benchmark Dataset for Retinal Detachment Classification in 3D Ocular Ultrasound (TBA)</a>
                              <br>
                              <a href="https://arxiv.org/abs/2404.10140">A Probabilistic-based Drift Correction Module for Visual Inertial SLAMs</a>
                           </td>
                        </tr>
                        <tr>
                           <td align="center" style="padding:16px;width:20%;vertical-align:middle">
                              <div class="colored-box" style="background-color: #c6b89e;">
                                 <h2>Academic Service</h2>
                              </div>
                           </td>
                           <td style="padding:8px;width:80%;vertical-align:center">
                              Reviewer for CVPR, ECCV, ICCV, ICLR, AVSS, ACCV, SIBGRAPI (2023-2025)
                           </td>
                        </tr>

                     </tbody>
                  </table>
                  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                     <tbody>
                        <tr>
                           <td style="padding:0px">
                              <br>
                              <p style="text-align:center;font-size:small;">
                                 Design and source code from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron's website</a>.
                              </p>
                           </td>
                        </tr>
                     </tbody>
                  </table>
               </td>
            </tr>
      </table>
   </body>
</html>
